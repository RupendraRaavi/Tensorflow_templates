{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af17d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94f893",
   "metadata": {},
   "source": [
    "## Importing the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fce5d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = pd.read_csv('https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af5fb7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca1e8a6",
   "metadata": {},
   "source": [
    "## Getting the dummies (Which is one hot encoding - First try this and then try normalized (Normalized might not work since the test dataset might be normalized) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69cabd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.get_dummies(insurance,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bea6b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data1= pd.get_dummies(insurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ccf749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>10600.54830</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>2205.98080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>1629.83350</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>2007.94500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>29141.36030</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children      charges  sex_male  smoker_yes  \\\n",
       "0      19  27.900         0  16884.92400         0           1   \n",
       "1      18  33.770         1   1725.55230         1           0   \n",
       "2      28  33.000         3   4449.46200         1           0   \n",
       "3      33  22.705         0  21984.47061         1           0   \n",
       "4      32  28.880         0   3866.85520         1           0   \n",
       "...   ...     ...       ...          ...       ...         ...   \n",
       "1333   50  30.970         3  10600.54830         1           0   \n",
       "1334   18  31.920         0   2205.98080         0           0   \n",
       "1335   18  36.850         0   1629.83350         0           0   \n",
       "1336   21  25.800         0   2007.94500         0           0   \n",
       "1337   61  29.070         0  29141.36030         0           1   \n",
       "\n",
       "      region_northwest  region_southeast  region_southwest  \n",
       "0                    0                 0                 1  \n",
       "1                    0                 1                 0  \n",
       "2                    0                 1                 0  \n",
       "3                    1                 0                 0  \n",
       "4                    1                 0                 0  \n",
       "...                ...               ...               ...  \n",
       "1333                 1                 0                 0  \n",
       "1334                 0                 0                 0  \n",
       "1335                 0                 1                 0  \n",
       "1336                 0                 0                 1  \n",
       "1337                 1                 0                 0  \n",
       "\n",
       "[1338 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbc2ea1",
   "metadata": {},
   "source": [
    "## Creating the X and y values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13bc2719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and Y values\n",
    "X= my_data.drop('charges', axis = 1)\n",
    "y = my_data['charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a308f9d0",
   "metadata": {},
   "source": [
    "## Splitting the variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b6f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca095aa0",
   "metadata": {},
   "source": [
    "## Model_checkpoint - callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e303bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "def create_model_checkpoint(model_name , save_path = 'model_experiments'):\n",
    "    return tf.keras.callbacks.ModelCheckpoint(filepath = os.path.join(save_path, model_name),\n",
    "                                             verbosity = 0, # Not print the output,\n",
    "                                             save_best_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0667eb2",
   "metadata": {},
   "source": [
    "## Creating the model (By keeping the model checkpoint) -- Need to keep the validation for checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d24291d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "34/34 [==============================] - 1s 11ms/step - loss: 13083.9482 - mae: 13083.9482 - val_loss: 12229.7402 - val_mae: 12229.7402 - lr: 0.0100\n",
      "Epoch 2/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 11659.4551 - mae: 11659.4551 - val_loss: 10012.2812 - val_mae: 10012.2812 - lr: 0.0100\n",
      "Epoch 3/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9054.3057 - mae: 9054.3057 - val_loss: 7820.0996 - val_mae: 7820.0996 - lr: 0.0100\n",
      "Epoch 4/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7528.3853 - mae: 7528.3853 - val_loss: 7567.9399 - val_mae: 7567.9399 - lr: 0.0100\n",
      "Epoch 5/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7421.9170 - mae: 7421.9170 - val_loss: 7520.9004 - val_mae: 7520.9004 - lr: 0.0100\n",
      "Epoch 6/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7430.1216 - mae: 7430.1216 - val_loss: 7473.5859 - val_mae: 7473.5859 - lr: 0.0100\n",
      "Epoch 7/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7385.5376 - mae: 7385.5376 - val_loss: 7421.1616 - val_mae: 7421.1616 - lr: 0.0100\n",
      "Epoch 8/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7372.4727 - mae: 7372.4727 - val_loss: 7371.4766 - val_mae: 7371.4766 - lr: 0.0100\n",
      "Epoch 9/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7323.8711 - mae: 7323.8711 - val_loss: 7321.7686 - val_mae: 7321.7686 - lr: 0.0100\n",
      "Epoch 10/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7298.9595 - mae: 7298.9595 - val_loss: 7263.1094 - val_mae: 7263.1094 - lr: 0.0100\n",
      "Epoch 11/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7246.5166 - mae: 7246.5166 - val_loss: 7208.4180 - val_mae: 7208.4180 - lr: 0.0100\n",
      "Epoch 12/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7207.2490 - mae: 7207.2490 - val_loss: 7148.6733 - val_mae: 7148.6733 - lr: 0.0100\n",
      "Epoch 13/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7124.2349 - mae: 7124.2349 - val_loss: 7088.4775 - val_mae: 7088.4775 - lr: 0.0100\n",
      "Epoch 14/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7138.3408 - mae: 7138.3408 - val_loss: 7027.0820 - val_mae: 7027.0820 - lr: 0.0100\n",
      "Epoch 15/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7077.2573 - mae: 7077.2573 - val_loss: 6971.0410 - val_mae: 6971.0410 - lr: 0.0100\n",
      "Epoch 16/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7039.1304 - mae: 7039.1304 - val_loss: 6904.2056 - val_mae: 6904.2056 - lr: 0.0100\n",
      "Epoch 17/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6943.2622 - mae: 6943.2622 - val_loss: 6830.9946 - val_mae: 6830.9946 - lr: 0.0100\n",
      "Epoch 18/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6954.5244 - mae: 6954.5244 - val_loss: 6763.3477 - val_mae: 6763.3477 - lr: 0.0100\n",
      "Epoch 19/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6877.6128 - mae: 6877.6128 - val_loss: 6692.0000 - val_mae: 6692.0000 - lr: 0.0100\n",
      "Epoch 20/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6831.8184 - mae: 6831.8184 - val_loss: 6626.7534 - val_mae: 6626.7534 - lr: 0.0100\n",
      "Epoch 21/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6766.7173 - mae: 6766.7173 - val_loss: 6567.2344 - val_mae: 6567.2344 - lr: 0.0100\n",
      "Epoch 22/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6780.4453 - mae: 6780.4453 - val_loss: 6520.1504 - val_mae: 6520.1504 - lr: 0.0100\n",
      "Epoch 23/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6743.3154 - mae: 6743.3154 - val_loss: 6467.2251 - val_mae: 6467.2251 - lr: 0.0100\n",
      "Epoch 24/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6705.3750 - mae: 6705.3750 - val_loss: 6445.0532 - val_mae: 6445.0532 - lr: 0.0100\n",
      "Epoch 25/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6678.1650 - mae: 6678.1650 - val_loss: 6400.9502 - val_mae: 6400.9502 - lr: 0.0100\n",
      "Epoch 26/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6697.8550 - mae: 6697.8550 - val_loss: 6393.6899 - val_mae: 6393.6899 - lr: 0.0100\n",
      "Epoch 27/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6643.6592 - mae: 6643.6592 - val_loss: 6361.5420 - val_mae: 6361.5420 - lr: 0.0100\n",
      "Epoch 28/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6649.8638 - mae: 6649.8638 - val_loss: 6336.8237 - val_mae: 6336.8237 - lr: 0.0100\n",
      "Epoch 29/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6628.2310 - mae: 6628.2310 - val_loss: 6341.2168 - val_mae: 6341.2168 - lr: 0.0100\n",
      "Epoch 30/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6587.8379 - mae: 6587.8379 - val_loss: 6304.8823 - val_mae: 6304.8823 - lr: 0.0100\n",
      "Epoch 31/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6578.0400 - mae: 6578.0400 - val_loss: 6311.7959 - val_mae: 6311.7959 - lr: 0.0100\n",
      "Epoch 32/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6564.7114 - mae: 6564.7114 - val_loss: 6272.1147 - val_mae: 6272.1147 - lr: 0.0100\n",
      "Epoch 33/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6573.9248 - mae: 6573.9248 - val_loss: 6257.6777 - val_mae: 6257.6777 - lr: 0.0100\n",
      "Epoch 34/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 6505.2329 - mae: 6505.2329 - val_loss: 6248.8486 - val_mae: 6248.8486 - lr: 0.0100\n",
      "Epoch 35/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 6524.7930 - mae: 6524.7930 - val_loss: 6231.3301 - val_mae: 6231.3301 - lr: 0.0100\n",
      "Epoch 36/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6500.2056 - mae: 6500.2056 - val_loss: 6222.8853 - val_mae: 6222.8853 - lr: 0.0100\n",
      "Epoch 37/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6485.7451 - mae: 6485.7451 - val_loss: 6185.1553 - val_mae: 6185.1553 - lr: 0.0100\n",
      "Epoch 38/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6444.6953 - mae: 6444.6953 - val_loss: 6167.3779 - val_mae: 6167.3779 - lr: 0.0100\n",
      "Epoch 39/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6467.4907 - mae: 6467.4907 - val_loss: 6150.3970 - val_mae: 6150.3970 - lr: 0.0100\n",
      "Epoch 40/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6411.1553 - mae: 6411.1553 - val_loss: 6130.2280 - val_mae: 6130.2280 - lr: 0.0100\n",
      "Epoch 41/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6375.2886 - mae: 6375.2886 - val_loss: 6153.9619 - val_mae: 6153.9619 - lr: 0.0100\n",
      "Epoch 42/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6422.2271 - mae: 6422.2271 - val_loss: 6130.8042 - val_mae: 6130.8042 - lr: 0.0100\n",
      "Epoch 43/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6372.4541 - mae: 6372.4541 - val_loss: 6079.5342 - val_mae: 6079.5342 - lr: 0.0100\n",
      "Epoch 44/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6342.6123 - mae: 6342.6123 - val_loss: 6083.2847 - val_mae: 6083.2847 - lr: 0.0100\n",
      "Epoch 45/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6349.0381 - mae: 6349.0381 - val_loss: 6062.8911 - val_mae: 6062.8911 - lr: 0.0100\n",
      "Epoch 46/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 6311.4946 - mae: 6311.4946 - val_loss: 6056.2505 - val_mae: 6056.2505 - lr: 0.0100\n",
      "Epoch 47/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 6282.2832 - mae: 6282.2832 - val_loss: 6001.9224 - val_mae: 6001.9224 - lr: 0.0100\n",
      "Epoch 48/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6283.1626 - mae: 6283.1626 - val_loss: 5969.3218 - val_mae: 5969.3218 - lr: 0.0100\n",
      "Epoch 49/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6254.6289 - mae: 6254.6289 - val_loss: 5944.5669 - val_mae: 5944.5669 - lr: 0.0100\n",
      "Epoch 50/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6249.5938 - mae: 6249.5938 - val_loss: 5919.7861 - val_mae: 5919.7861 - lr: 0.0100\n",
      "Epoch 51/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6222.8970 - mae: 6222.8970 - val_loss: 5920.2920 - val_mae: 5920.2920 - lr: 0.0100\n",
      "Epoch 52/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 6206.8071 - mae: 6206.8071 - val_loss: 5879.6196 - val_mae: 5879.6196 - lr: 0.0100\n",
      "Epoch 53/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6139.2192 - mae: 6139.2192 - val_loss: 5871.3271 - val_mae: 5871.3271 - lr: 0.0100\n",
      "Epoch 54/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 6109.4614 - mae: 6109.4614 - val_loss: 5827.0679 - val_mae: 5827.0679 - lr: 0.0100\n",
      "Epoch 55/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 6134.6094 - mae: 6134.6094 - val_loss: 5793.5068 - val_mae: 5793.5068 - lr: 0.0100\n",
      "Epoch 56/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6083.6733 - mae: 6083.6733 - val_loss: 5757.9634 - val_mae: 5757.9634 - lr: 0.0100\n",
      "Epoch 57/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6043.9922 - mae: 6043.9922 - val_loss: 5725.2275 - val_mae: 5725.2275 - lr: 0.0100\n",
      "Epoch 58/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6030.8857 - mae: 6030.8857 - val_loss: 5694.1543 - val_mae: 5694.1543 - lr: 0.0100\n",
      "Epoch 59/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5953.1323 - mae: 5953.1323 - val_loss: 5660.3311 - val_mae: 5660.3311 - lr: 0.0100\n",
      "Epoch 60/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 5928.3457 - mae: 5928.3457 - val_loss: 5637.1055 - val_mae: 5637.1055 - lr: 0.0100\n",
      "Epoch 61/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5921.4688 - mae: 5921.4688 - val_loss: 5589.3008 - val_mae: 5589.3008 - lr: 0.0100\n",
      "Epoch 62/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5875.9517 - mae: 5875.9517 - val_loss: 5550.2397 - val_mae: 5550.2397 - lr: 0.0100\n",
      "Epoch 63/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5816.6924 - mae: 5816.6924 - val_loss: 5544.4810 - val_mae: 5544.4810 - lr: 0.0100\n",
      "Epoch 64/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5754.1689 - mae: 5754.1689 - val_loss: 5515.0347 - val_mae: 5515.0347 - lr: 0.0100\n",
      "Epoch 65/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5728.0225 - mae: 5728.0225 - val_loss: 5428.2861 - val_mae: 5428.2861 - lr: 0.0100\n",
      "Epoch 66/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5705.7036 - mae: 5705.7036 - val_loss: 5382.2988 - val_mae: 5382.2988 - lr: 0.0100\n",
      "Epoch 67/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5654.6284 - mae: 5654.6284 - val_loss: 5346.0356 - val_mae: 5346.0356 - lr: 0.0100\n",
      "Epoch 68/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5615.3530 - mae: 5615.3530 - val_loss: 5293.1548 - val_mae: 5293.1548 - lr: 0.0100\n",
      "Epoch 69/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5562.2637 - mae: 5562.2637 - val_loss: 5234.7021 - val_mae: 5234.7021 - lr: 0.0100\n",
      "Epoch 70/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5445.1021 - mae: 5445.1021 - val_loss: 5256.1675 - val_mae: 5256.1675 - lr: 0.0100\n",
      "Epoch 71/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5497.4995 - mae: 5497.4995 - val_loss: 5145.5254 - val_mae: 5145.5254 - lr: 0.0100\n",
      "Epoch 72/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5391.0283 - mae: 5391.0283 - val_loss: 5096.8184 - val_mae: 5096.8184 - lr: 0.0100\n",
      "Epoch 73/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5346.6084 - mae: 5346.6084 - val_loss: 5019.4663 - val_mae: 5019.4663 - lr: 0.0100\n",
      "Epoch 74/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5308.9238 - mae: 5308.9238 - val_loss: 4955.6196 - val_mae: 4955.6196 - lr: 0.0100\n",
      "Epoch 75/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5190.3984 - mae: 5190.3984 - val_loss: 4907.8320 - val_mae: 4907.8320 - lr: 0.0100\n",
      "Epoch 76/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5150.1958 - mae: 5150.1958 - val_loss: 4830.9062 - val_mae: 4830.9062 - lr: 0.0100\n",
      "Epoch 77/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5103.9141 - mae: 5103.9141 - val_loss: 4783.6938 - val_mae: 4783.6938 - lr: 0.0100\n",
      "Epoch 78/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5076.4805 - mae: 5076.4805 - val_loss: 4731.4844 - val_mae: 4731.4844 - lr: 0.0100\n",
      "Epoch 79/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4976.9810 - mae: 4976.9810 - val_loss: 4621.0913 - val_mae: 4621.0913 - lr: 0.0100\n",
      "Epoch 80/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 4853.3623 - mae: 4853.3623 - val_loss: 4570.9043 - val_mae: 4570.9043 - lr: 0.0100\n",
      "Epoch 81/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 4852.7412 - mae: 4852.7412 - val_loss: 4477.3511 - val_mae: 4477.3511 - lr: 0.0100\n",
      "Epoch 82/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4770.2505 - mae: 4770.2505 - val_loss: 4403.5728 - val_mae: 4403.5728 - lr: 0.0100\n",
      "Epoch 83/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4666.6685 - mae: 4666.6685 - val_loss: 4321.4775 - val_mae: 4321.4775 - lr: 0.0100\n",
      "Epoch 84/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4633.9521 - mae: 4633.9521 - val_loss: 4247.2178 - val_mae: 4247.2178 - lr: 0.0100\n",
      "Epoch 85/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4495.8813 - mae: 4495.8813 - val_loss: 4194.7627 - val_mae: 4194.7627 - lr: 0.0100\n",
      "Epoch 86/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4479.2021 - mae: 4479.2021 - val_loss: 4115.7549 - val_mae: 4115.7549 - lr: 0.0100\n",
      "Epoch 87/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4468.6226 - mae: 4468.6226 - val_loss: 4053.0032 - val_mae: 4053.0032 - lr: 0.0100\n",
      "Epoch 88/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4400.8916 - mae: 4400.8916 - val_loss: 3985.6521 - val_mae: 3985.6521 - lr: 0.0100\n",
      "Epoch 89/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4406.3594 - mae: 4406.3594 - val_loss: 3917.9907 - val_mae: 3917.9907 - lr: 0.0100\n",
      "Epoch 90/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4278.1753 - mae: 4278.1753 - val_loss: 3850.5447 - val_mae: 3850.5447 - lr: 0.0100\n",
      "Epoch 91/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4253.8091 - mae: 4253.8091 - val_loss: 3812.2109 - val_mae: 3812.2109 - lr: 0.0100\n",
      "Epoch 92/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4175.2339 - mae: 4175.2339 - val_loss: 3767.4626 - val_mae: 3767.4626 - lr: 0.0100\n",
      "Epoch 93/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4226.6562 - mae: 4226.6562 - val_loss: 3741.0181 - val_mae: 3741.0181 - lr: 0.0100\n",
      "Epoch 94/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 4132.2134 - mae: 4132.2134 - val_loss: 3719.8452 - val_mae: 3719.8452 - lr: 0.0100\n",
      "Epoch 95/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 4088.2417 - mae: 4088.2417 - val_loss: 3657.8030 - val_mae: 3657.8030 - lr: 0.0100\n",
      "Epoch 96/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 4090.9636 - mae: 4090.9636 - val_loss: 3610.7202 - val_mae: 3610.7202 - lr: 0.0100\n",
      "Epoch 97/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4053.3767 - mae: 4053.3767 - val_loss: 3616.1216 - val_mae: 3616.1216 - lr: 0.0100\n",
      "Epoch 98/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 4045.8723 - mae: 4045.8723 - val_loss: 3571.1072 - val_mae: 3571.1072 - lr: 0.0100\n",
      "Epoch 99/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4011.4131 - mae: 4011.4131 - val_loss: 3587.1748 - val_mae: 3587.1748 - lr: 0.0100\n",
      "Epoch 100/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3971.1079 - mae: 3971.1079 - val_loss: 3544.9819 - val_mae: 3544.9819 - lr: 0.0100\n",
      "Epoch 101/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3973.4055 - mae: 3973.4055 - val_loss: 3532.2852 - val_mae: 3532.2852 - lr: 0.0100\n",
      "Epoch 102/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3958.4856 - mae: 3958.4856 - val_loss: 3563.0764 - val_mae: 3563.0764 - lr: 0.0100\n",
      "Epoch 103/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3953.1509 - mae: 3953.1509 - val_loss: 3518.7473 - val_mae: 3518.7473 - lr: 0.0100\n",
      "Epoch 104/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3946.6799 - mae: 3946.6799 - val_loss: 3507.4021 - val_mae: 3507.4021 - lr: 0.0100\n",
      "Epoch 105/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 4ms/step - loss: 3933.8691 - mae: 3933.8691 - val_loss: 3500.7939 - val_mae: 3500.7939 - lr: 0.0100\n",
      "Epoch 106/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3941.3032 - mae: 3941.3032 - val_loss: 3507.6833 - val_mae: 3507.6833 - lr: 0.0100\n",
      "Epoch 107/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3940.8308 - mae: 3940.8308 - val_loss: 3488.4282 - val_mae: 3488.4282 - lr: 0.0100\n",
      "Epoch 108/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3982.1658 - mae: 3982.1658 - val_loss: 3491.0662 - val_mae: 3491.0662 - lr: 0.0100\n",
      "Epoch 109/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3936.3645 - mae: 3936.3645 - val_loss: 3527.9949 - val_mae: 3527.9949 - lr: 0.0100\n",
      "Epoch 110/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3872.3538 - mae: 3872.3538 - val_loss: 3459.0281 - val_mae: 3459.0281 - lr: 0.0100\n",
      "Epoch 111/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3916.2456 - mae: 3916.2456 - val_loss: 3469.2405 - val_mae: 3469.2405 - lr: 0.0100\n",
      "Epoch 112/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3842.4307 - mae: 3842.4307 - val_loss: 3460.0950 - val_mae: 3460.0950 - lr: 0.0100\n",
      "Epoch 113/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3897.9309 - mae: 3897.9309 - val_loss: 3444.2793 - val_mae: 3444.2793 - lr: 0.0100\n",
      "Epoch 114/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3868.7300 - mae: 3868.7300 - val_loss: 3530.4282 - val_mae: 3530.4282 - lr: 0.0100\n",
      "Epoch 115/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3885.4258 - mae: 3885.4258 - val_loss: 3452.2434 - val_mae: 3452.2434 - lr: 0.0100\n",
      "Epoch 116/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3840.1182 - mae: 3840.1182 - val_loss: 3447.5942 - val_mae: 3447.5942 - lr: 0.0100\n",
      "Epoch 117/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3925.6211 - mae: 3925.6211 - val_loss: 3446.1094 - val_mae: 3446.1094 - lr: 0.0100\n",
      "Epoch 118/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3846.4524 - mae: 3846.4524 - val_loss: 3425.3247 - val_mae: 3425.3247 - lr: 0.0100\n",
      "Epoch 119/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3859.4053 - mae: 3859.4053 - val_loss: 3420.3015 - val_mae: 3420.3015 - lr: 0.0100\n",
      "Epoch 120/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3846.2559 - mae: 3846.2559 - val_loss: 3414.9678 - val_mae: 3414.9678 - lr: 0.0100\n",
      "Epoch 121/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3821.6411 - mae: 3821.6411 - val_loss: 3448.5005 - val_mae: 3448.5005 - lr: 0.0100\n",
      "Epoch 122/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3781.3735 - mae: 3781.3735 - val_loss: 3409.5962 - val_mae: 3409.5962 - lr: 0.0100\n",
      "Epoch 123/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3800.0022 - mae: 3800.0022 - val_loss: 3411.7983 - val_mae: 3411.7983 - lr: 0.0100\n",
      "Epoch 124/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3831.7820 - mae: 3831.7820 - val_loss: 3414.8738 - val_mae: 3414.8738 - lr: 0.0100\n",
      "Epoch 125/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3810.3857 - mae: 3810.3857 - val_loss: 3406.5303 - val_mae: 3406.5303 - lr: 0.0100\n",
      "Epoch 126/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3821.3667 - mae: 3821.3667 - val_loss: 3404.4890 - val_mae: 3404.4890 - lr: 0.0100\n",
      "Epoch 127/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3827.4238 - mae: 3827.4238 - val_loss: 3423.1929 - val_mae: 3423.1929 - lr: 0.0100\n",
      "Epoch 128/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3837.7288 - mae: 3837.7288 - val_loss: 3438.8577 - val_mae: 3438.8577 - lr: 0.0100\n",
      "Epoch 129/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3789.0952 - mae: 3789.0952 - val_loss: 3402.7334 - val_mae: 3402.7334 - lr: 0.0100\n",
      "Epoch 130/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3845.9753 - mae: 3845.9753 - val_loss: 3392.2163 - val_mae: 3392.2163 - lr: 0.0100\n",
      "Epoch 131/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3792.3977 - mae: 3792.3977 - val_loss: 3380.5823 - val_mae: 3380.5823 - lr: 0.0100\n",
      "Epoch 132/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3787.1191 - mae: 3787.1191 - val_loss: 3389.2720 - val_mae: 3389.2720 - lr: 0.0100\n",
      "Epoch 133/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3795.4441 - mae: 3795.4441 - val_loss: 3374.1343 - val_mae: 3374.1343 - lr: 0.0100\n",
      "Epoch 134/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3830.7156 - mae: 3830.7156 - val_loss: 3369.5701 - val_mae: 3369.5701 - lr: 0.0100\n",
      "Epoch 135/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3848.6196 - mae: 3848.6196 - val_loss: 3375.2336 - val_mae: 3375.2336 - lr: 0.0100\n",
      "Epoch 136/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3841.8813 - mae: 3841.8813 - val_loss: 3354.8735 - val_mae: 3354.8735 - lr: 0.0100\n",
      "Epoch 137/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3767.1494 - mae: 3767.1494 - val_loss: 3400.3323 - val_mae: 3400.3323 - lr: 0.0100\n",
      "Epoch 138/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3830.4155 - mae: 3830.4155 - val_loss: 3372.6079 - val_mae: 3372.6079 - lr: 0.0100\n",
      "Epoch 139/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3839.0198 - mae: 3839.0198 - val_loss: 3339.4805 - val_mae: 3339.4805 - lr: 0.0100\n",
      "Epoch 140/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3786.1362 - mae: 3786.1362 - val_loss: 3341.9128 - val_mae: 3341.9128 - lr: 0.0100\n",
      "Epoch 141/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3793.5291 - mae: 3793.5291 - val_loss: 3410.8831 - val_mae: 3410.8831 - lr: 0.0100\n",
      "Epoch 142/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3733.1831 - mae: 3733.1831 - val_loss: 3341.1265 - val_mae: 3341.1265 - lr: 0.0100\n",
      "Epoch 143/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3824.6921 - mae: 3824.6921 - val_loss: 3389.7976 - val_mae: 3389.7976 - lr: 0.0100\n",
      "Epoch 144/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3729.0085 - mae: 3729.0085 - val_loss: 3356.8765 - val_mae: 3356.8765 - lr: 0.0100\n",
      "Epoch 145/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3739.1016 - mae: 3739.1016 - val_loss: 3338.0574 - val_mae: 3338.0574 - lr: 0.0100\n",
      "Epoch 146/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3783.5864 - mae: 3783.5864 - val_loss: 3321.7004 - val_mae: 3321.7004 - lr: 0.0100\n",
      "Epoch 147/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3712.1426 - mae: 3712.1426 - val_loss: 3330.0918 - val_mae: 3330.0918 - lr: 0.0100\n",
      "Epoch 148/150\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3720.2124 - mae: 3720.2124 - val_loss: 3317.9426 - val_mae: 3317.9426 - lr: 0.0100\n",
      "Epoch 149/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3766.8176 - mae: 3766.8176 - val_loss: 3425.2043 - val_mae: 3425.2043 - lr: 0.0100\n",
      "Epoch 150/150\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3824.8684 - mae: 3824.8684 - val_loss: 3323.1604 - val_mae: 3323.1604 - lr: 0.0100\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100,activation  = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.Adam(learning_rate= 0.01),\n",
    "              metrics= ['mae'])\n",
    "\n",
    "#Creating a learning reduce on plateu callback\n",
    "\n",
    "rpc = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "history =  model.fit(X_train,y_train,epochs = 150, validation_data = (X_test, y_test),callbacks = [create_model_checkpoint(model_name='dense.h5'), rpc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2968c7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 3323.1604 - mae: 3323.1604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3323.160400390625, 3323.160400390625]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782e48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "3109.3633"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e789299",
   "metadata": {},
   "source": [
    "## Loading the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4006349",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.load_model('model_experiments/dense.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16b92c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 3315.8218 - mae: 3315.8218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3315.82177734375, 3315.82177734375]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00aec7f",
   "metadata": {},
   "source": [
    "## Creating the graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "394a569a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13083.948242</td>\n",
       "      <td>13083.948242</td>\n",
       "      <td>12229.740234</td>\n",
       "      <td>12229.740234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11659.455078</td>\n",
       "      <td>11659.455078</td>\n",
       "      <td>10012.281250</td>\n",
       "      <td>10012.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9054.305664</td>\n",
       "      <td>9054.305664</td>\n",
       "      <td>7820.099609</td>\n",
       "      <td>7820.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7528.385254</td>\n",
       "      <td>7528.385254</td>\n",
       "      <td>7567.939941</td>\n",
       "      <td>7567.939941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7421.916992</td>\n",
       "      <td>7421.916992</td>\n",
       "      <td>7520.900391</td>\n",
       "      <td>7520.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>3647.941650</td>\n",
       "      <td>3647.941650</td>\n",
       "      <td>3101.636475</td>\n",
       "      <td>3101.636475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>3668.247314</td>\n",
       "      <td>3668.247314</td>\n",
       "      <td>3181.893311</td>\n",
       "      <td>3181.893311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>3645.516357</td>\n",
       "      <td>3645.516357</td>\n",
       "      <td>3113.838135</td>\n",
       "      <td>3113.838135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>3669.131348</td>\n",
       "      <td>3669.131348</td>\n",
       "      <td>3120.349121</td>\n",
       "      <td>3120.349121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>3683.780762</td>\n",
       "      <td>3683.780762</td>\n",
       "      <td>3109.363281</td>\n",
       "      <td>3109.363281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss           mae      val_loss       val_mae\n",
       "0    13083.948242  13083.948242  12229.740234  12229.740234\n",
       "1    11659.455078  11659.455078  10012.281250  10012.281250\n",
       "2     9054.305664   9054.305664   7820.099609   7820.099609\n",
       "3     7528.385254   7528.385254   7567.939941   7567.939941\n",
       "4     7421.916992   7421.916992   7520.900391   7520.900391\n",
       "..            ...           ...           ...           ...\n",
       "245   3647.941650   3647.941650   3101.636475   3101.636475\n",
       "246   3668.247314   3668.247314   3181.893311   3181.893311\n",
       "247   3645.516357   3645.516357   3113.838135   3113.838135\n",
       "248   3669.131348   3669.131348   3120.349121   3120.349121\n",
       "249   3683.780762   3683.780762   3109.363281   3109.363281\n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "a = pd.DataFrame(history.history)\n",
    "a\n",
    "c = a.loc[:,['Accuracy','val_Accuracy']].plot(title = 'Not_normalized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c79270",
   "metadata": {},
   "source": [
    "## Normalizing and onehot encoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96d673dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Create a column transformer\n",
    "\n",
    "ct = make_column_transformer((MinMaxScaler(), ['age','bmi','children']),\n",
    "                            (OneHotEncoder(handle_unknown='ignore'),['sex','smoker','region'])\n",
    "                            )\n",
    "\n",
    "\n",
    "#Create X and y\n",
    "\n",
    "X = insurance_new.drop('charges',axis = 1)\n",
    "y = insurance_new['charges']\n",
    "\n",
    "# Train and test split\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X,y , test_size = 0.2 , random_state = 42)\n",
    "\n",
    "\n",
    "# Fit the model -- Which mean's only the training values are considered such as in\n",
    "#min max scalar minimum and max values are taken to normalize everything.\n",
    "#so only the training min and max values are taken into consideration in this step only values are \n",
    "#calulated but transormation is done in the transformation step\n",
    "\n",
    "ct.fit(X_train)\n",
    "\n",
    "# Transform the value\n",
    "\n",
    "X_train_normal = ct.transform(X_train)\n",
    "\n",
    "X_test_normal = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5b007b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = my_data.drop('y', axis = 1), X = my_data.drop('ID', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5aaba85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X = X.drop('y', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "053eda8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81a6d89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>...</th>\n",
       "      <th>X8_p</th>\n",
       "      <th>X8_q</th>\n",
       "      <th>X8_r</th>\n",
       "      <th>X8_s</th>\n",
       "      <th>X8_t</th>\n",
       "      <th>X8_u</th>\n",
       "      <th>X8_v</th>\n",
       "      <th>X8_w</th>\n",
       "      <th>X8_x</th>\n",
       "      <th>X8_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4209 rows × 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X10  X11  X12  X13  X14  X15  X16  X17  X18  X19  ...  X8_p  X8_q  X8_r  \\\n",
       "0       0    0    0    1    0    0    0    0    1    0  ...     0     0     0   \n",
       "1       0    0    0    0    0    0    0    0    1    0  ...     0     0     0   \n",
       "2       0    0    0    0    0    0    0    1    0    0  ...     0     0     0   \n",
       "3       0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "4       0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "4204    0    0    0    0    1    0    0    0    0    0  ...     0     1     0   \n",
       "4205    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "4206    0    0    1    1    0    0    0    0    0    0  ...     0     0     0   \n",
       "4207    0    0    0    0    1    0    0    0    0    0  ...     0     0     0   \n",
       "4208    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "\n",
       "      X8_s  X8_t  X8_u  X8_v  X8_w  X8_x  X8_y  \n",
       "0        0     0     0     0     0     0     0  \n",
       "1        0     0     0     0     0     0     0  \n",
       "2        0     0     0     0     0     1     0  \n",
       "3        0     0     0     0     0     0     0  \n",
       "4        0     0     0     0     0     0     0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...  \n",
       "4204     0     0     0     0     0     0     0  \n",
       "4205     0     0     0     0     0     0     0  \n",
       "4206     0     0     0     0     0     0     0  \n",
       "4207     0     0     1     0     0     0     0  \n",
       "4208     0     0     0     0     1     0     0  \n",
       "\n",
       "[4209 rows x 563 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf25274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
